{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59995a75-7e03-4498-9a95-8a405a3b035c",
   "metadata": {},
   "source": [
    "# Boston Housing Regression: Ensemble Models Comparison\n",
    "\n",
    "This notebook demonstrates the comparison of various regression models and ensemble techniques on the **Boston Housing dataset**. The goal is to predict the median value of owner-occupied homes (`medv`) using the available features.  \n",
    "\n",
    "We will explore the following models:\n",
    "\n",
    "- **Linear Regression** with proper handling of categorical variables (`chas` and `rad`) via One-Hot Encoding.\n",
    "- **Decision Tree Regressor**, which splits data to reduce MSE at each node.\n",
    "- **Bagging Regressor** using Decision Trees to reduce variance.\n",
    "- **AdaBoost Regressor**, boosting weak learners to improve prediction accuracy.\n",
    "- **Extra Trees Regressor**, an ensemble of randomized decision trees that reduces variance and improves robustness.\n",
    "- **Voting Regressor**, combining Linear Regression and Decision Tree predictions for improved generalization.\n",
    "\n",
    "Key steps:\n",
    "\n",
    "1. **Data Preprocessing**: Scaling numeric features and encoding categorical features using `ColumnTransformer`.\n",
    "2. **Model Training**: Using pipelines to ensure preprocessing is applied consistently where required.\n",
    "3. **Cross-Validation**: 5-fold CV to estimate model performance on unseen data.\n",
    "4. **Evaluation Metrics**: RÂ² score on training, test, and cross-validated predictions to check overfitting and generalization.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- Extra Trees differs from Bagging by using **random feature selection** and **random split thresholds**, often resulting in lower variance.\n",
    "- All ensemble models are evaluated using consistent cross-validation to ensure fair comparison.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- Boston Housing Dataset: [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/Boston+Housing)\n",
    "- Scikit-learn Ensemble Methods: [Bagging, AdaBoost, Extra Trees, Voting](https://scikit-learn.org/stable/modules/ensemble.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c113f59-9cc8-461e-9e91-e75e49c59e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c132d7e-d5ee-45f3-81e5-9ec74f88eb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV R2</th>\n",
       "      <th>Std CV R2</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost (DT)</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.9481</td>\n",
       "      <td>0.7726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging (DT)</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.7298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting Regressor</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.7809</td>\n",
       "      <td>0.5684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Mean CV R2  Std CV R2  Train R2  Test R2\n",
       "4        Extra Trees      0.8823     0.0734    1.0000   0.7208\n",
       "3      AdaBoost (DT)      0.8478     0.0886    0.9481   0.7726\n",
       "2       Bagging (DT)      0.8270     0.1023    0.9663   0.7298\n",
       "5   Voting Regressor      0.7930     0.1138    0.9452   0.6518\n",
       "0  Linear Regression      0.7388     0.0859    0.7809   0.5684\n",
       "1      Decision Tree      0.6823     0.1272    1.0000   0.4901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"D:\\OneDrive - greatlakes.edu.in\\OFFICE\\ML\\Datasets/Boston.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=28\n",
    ")\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "cat_cols = ['chas', 'rad']\n",
    "num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "\n",
    "# Convert categorical columns to 'category' dtype\n",
    "X_train[cat_cols] = X_train[cat_cols].astype('category')\n",
    "X_test[cat_cols] = X_test[cat_cols].astype('category')\n",
    "\n",
    "# Column transformer for scaling numerical and one-hot encoding categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define regression models\n",
    "models = {\n",
    "    \"Linear Regression\": make_pipeline(\n",
    "        preprocessor,\n",
    "        LinearRegression()\n",
    "    ),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=28),\n",
    "    \"Bagging (DT)\": BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(random_state=28),\n",
    "        n_estimators=20,\n",
    "        max_samples=0.8,\n",
    "        oob_score=True,\n",
    "        random_state=28\n",
    "    ),\n",
    "    \"AdaBoost (DT)\": AdaBoostRegressor(\n",
    "        estimator=DecisionTreeRegressor(max_depth=4, random_state=28),\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.5,\n",
    "        random_state=28\n",
    "    ),\n",
    "    \"Extra Trees\": ExtraTreesRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=28,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"Voting Regressor\": VotingRegressor(\n",
    "        estimators=[\n",
    "            ('linear', make_pipeline(preprocessor, LinearRegression())),\n",
    "            ('dt', DecisionTreeRegressor(random_state=28))\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=28)\n",
    "\n",
    "# Evaluate each model\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([(\"model\", model)])\n",
    "    \n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train, y_train, cv=cv, scoring='r2', n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit model on full training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate R2 on training and test sets\n",
    "    train_r2 = r2_score(y_train, pipeline.predict(X_train))\n",
    "    test_r2 = r2_score(y_test, pipeline.predict(X_test))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Mean CV R2\": cv_scores.mean(),\n",
    "        \"Std CV R2\": cv_scores.std(),\n",
    "        \"Train R2\": train_r2,\n",
    "        \"Test R2\": test_r2\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "cv_summary = pd.DataFrame(results).sort_values(by=\"Mean CV R2\", ascending=False)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.4f}\")\n",
    "display(cv_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfc4d9-2691-4911-98f2-755288b65937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
